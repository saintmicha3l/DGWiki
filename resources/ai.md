# Artificial Intelligence

This section lists platforms and tools that allow you to **leverage AI and Large Language Models (LLMs)** directly in your workflow.  
These resources are commonly used for research, coding assistance, automation, analysis, experimentation, and model deployment.

> Use responsibly, respect licensing, and verify any data shared with AI tools.

---

## General-Purpose LLMs & APIs

- [OpenAI (ChatGPT / API)](https://openai.com)  
  General-purpose LLMs for reasoning, coding, writing, analysis, and automation. Includes API access for **custom integrations and tooling**.

- [Anthropic (Claude)](https://www.anthropic.com)  
  LLM optimized for long-context reasoning, document analysis, and structured outputs. Ideal for research-heavy workflows.

- [Google Gemini](https://gemini.google.com)  
  Googleâ€™s multimodal LLM with **search integration and reasoning capabilities**.

- [Microsoft Copilot](https://copilot.microsoft.com)  
  LLM integration across Windows, Office, and development tools. Useful for **productivity, code completion, and workflow automation**.

- [Perplexity AI](https://www.perplexity.ai)  
  AI-powered search and research assistant providing **source-backed answers**. Useful for reconnaissance, learning, and quick validation.

---

## Open-Source & Self-Hosted Models

- [Hugging Face](https://huggingface.co)  
  Platform for **open-source models, datasets, and inference APIs**. Ideal for experimenting with and deploying custom LLMs and ML models.

- [OpenRouter](https://openrouter.ai)  
  Unified API access to **multiple LLM providers and models**, useful for comparing outputs and building flexible AI tooling.

- [LM Studio](https://lmstudio.ai)  
  Run LLMs **locally on your machine**, supporting multiple open models for offline or private workflows.

- [Ollama](https://ollama.com)  
  Lightweight local LLM execution. Useful for **air-gapped, private, or experimental setups**.

---

## High-Performance & Enterprise LLMs

- [Mistral AI](https://mistral.ai)  
  Open and commercial LLMs focused on **efficiency and performance**, including self-hosted deployment options.

- [Groq](https://groq.com)  
  High-performance inference platform offering **extremely fast LLM response times** for supported models.

- [Cohere](https://cohere.com)  
  Enterprise-focused LLMs optimized for **embeddings, search, classification, and text generation**.

---

## Datasets & Experimentation

- [Kaggle](https://www.kaggle.com)  
  Hosting for datasets, notebooks, and ML competitions. Excellent for **model training, experimentation, and AI research**.

---

### Notes

- Many platforms offer **free tiers** or community editions for experimentation.  
- Self-hosted solutions allow **privacy, offline usage, and custom fine-tuning**.  
- Choose the platform that aligns with your **workflow, data sensitivity, and compute resources**.

